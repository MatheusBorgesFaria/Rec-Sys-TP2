{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disentangled Multimodal Representation Learning for Recommendation (DMRL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideias:\n",
    "- tunar os hiperparametros\n",
    "- paralelizar a previsao\n",
    "- Adicionar a coluna do assunto em conjunto com o texto\n",
    "- Limpar os dados de conteudo\n",
    "- usa a imagem alem do texto\n",
    "- renomear as colunas para ter um nome mais representativo para o bert\n",
    "- usar algum algoritmo mais simples apenas para usuarios novos, knn para content based\n",
    "- ordenar os itens novos que ficaram por ultimo por popularidade \n",
    "- Entender o parametro exclude_unknowns=True do RatioSplit e se tem alguma forma do DMRL gerar previsoes para itens e usuarios novos \n",
    "\n",
    "Perguntas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/miniconda/envs/sistema_recomendacao_tp2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cornac\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cornac.metrics import NDCG\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.data import TextModality\n",
    "from cornac.models.dmrl.recom_dmrl import DMRL\n",
    "\n",
    "from utils import load_data, preprocessing_content_data\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, content, targets = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"TimestampDate\"] = ratings['Timestamp'].dt.date\n",
    "ratings.loc[ratings.Rating == 0, \"Rating\"] = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpar os dados\n",
    "\n",
    "- FEITO - Year: deletar o - no texto '2013–'\n",
    "- FEITO - Rated: alterar as diversas formas de escrever NA para NA. Esse e um caso especial\n",
    "- FEITO - alterar as diversas formas de escrever NA para None em todas as coluans\n",
    "- FEITO - Language: tem varias linhas que possuem bizarices como  'None, English' e 'None, French' , 'English, None'...\n",
    "- FEITO - Ratings: criar uma coluna para cada chave do dicionario, entender quais sao todas as chaves que existem\n",
    "\n",
    "-----------------------------------------------\n",
    "Variaveis qwue nao precisariam ser tratadas com um bert:\n",
    "- Metascore\n",
    "- imdbRating\n",
    "- Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar = content.drop(columns=[\"Poster\", \"Website\", \"Response\", \"Episode\", \"seriesID\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar['Year'] = content_auxiliar['Year'].str.replace('–', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = content.totalSeasons.unique()[0]\n",
    "dict_transform_to_na = {\n",
    "    \"Rated\":['N/A', 'Not Rated', 'Unrated', 'UNRATED', 'NOT RATED'],\n",
    "    \"all\": [nan, 'N/A', 'None', np.nan],\n",
    "}\n",
    "\n",
    "for na_value in dict_transform_to_na[\"all\"]:\n",
    "    content_auxiliar = content_auxiliar.replace(na_value, None)\n",
    "\n",
    "for na_value in dict_transform_to_na[\"Rated\"]:\n",
    "    content_auxiliar['Rated'] = content_auxiliar['Rated'].replace(na_value, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar['Language'] = content_auxiliar['Language'].str.replace('None, ', '')\n",
    "content_auxiliar['Language'] = content_auxiliar['Language'].str.replace(', None', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Internet Movie Database', 'Metacritic', 'Rotten Tomatoes'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entendendo os valores possiveis para a coluna Ratings\n",
    "# A coluna content_auxiliar.Ratings quarda uma lista que posde ter entre 0 e 3 dicionarios. Cada dicionario possui a chave 'Source', 'Value'.\n",
    "num_ratings_per_item = []\n",
    "unique_keys = []\n",
    "rating_sources = []\n",
    "rating_values = []\n",
    "\n",
    "for rating_list in content_auxiliar.Ratings:\n",
    "    num_ratings_per_item.append(len(rating_list))\n",
    "    for rating_dict in rating_list:\n",
    "        for key in rating_dict:\n",
    "            unique_keys.append(key)\n",
    "        rating_sources.append(rating_dict['Source'])\n",
    "        rating_values.append(rating_dict['Value'])\n",
    "\n",
    "set(rating_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "InternetMovieDatabase_list = []\n",
    "Metacritic_list = []\n",
    "RottenTomatoes_list = []\n",
    "for rating_list in content_auxiliar.Ratings:\n",
    "    InternetMovieDatabase_list.append(None)\n",
    "    Metacritic_list.append(None)\n",
    "    RottenTomatoes_list.append(None)\n",
    "    for rating_dict in rating_list:\n",
    "        if rating_dict['Source'] == 'Internet Movie Database':\n",
    "            InternetMovieDatabase_list[-1] = rating_dict['Value']\n",
    "        elif rating_dict['Source'] == 'Metacritic':\n",
    "            Metacritic_list[-1] = rating_dict['Value']\n",
    "        elif rating_dict['Source'] == 'Rotten Tomatoes':\n",
    "            RottenTomatoes_list[-1] = rating_dict['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar['Internet Movie Database'] = InternetMovieDatabase_list\n",
    "content_auxiliar['Metacritic'] = Metacritic_list\n",
    "content_auxiliar['Rotten Tomatoes'] = RottenTomatoes_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar.drop(columns=['Ratings'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apendar a coluna no valor do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ItemId'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_columns = content_auxiliar.columns.to_list()\n",
    "content_columns.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in content_columns:\n",
    "    content_auxiliar[column] = content_auxiliar[column].apply(lambda x: f\"{column}: {x}; \" if x is not None else f\"{column}: unknown value; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_processed = content_auxiliar[['ItemId']].copy()\n",
    "content_processed[\"text\"] = content_auxiliar[content_columns].astype(str).fillna('').agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique users and items\n",
    "ratings.UserId.nunique(), ratings.ItemId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many itens purchased by each user purchase\n",
    "ratings.groupby([\"UserId\", 'Timestamp'])[\"ItemId\"].nunique().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many itens purchased by each user day by day\n",
    "ratings.groupby([\"UserId\", 'TimestampDate'])[\"ItemId\"].nunique().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many times each user purchased items\n",
    "ratings.groupby(\"UserId\")['Timestamp'].nunique().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many times each user purchased items per day\n",
    "ratings.groupby(\"UserId\")['TimestampDate'].nunique().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.Rating.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_text_modality = TextModality(\n",
    "    corpus=content_processed.text.to_list(),\n",
    "    ids=content_processed.ItemId.to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_threshold = 0.5\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 46750\n",
      "Number of items = 27045\n",
      "Number of ratings = 527776\n",
      "Max rating = 10.0\n",
      "Min rating = 0.0\n",
      "Global mean = 7.3\n",
      "---\n",
      "Test data:\n",
      "Number of users = 46750\n",
      "Number of items = 27045\n",
      "Number of ratings = 124031\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Total users = 46750\n",
      "Total items = 27045\n"
     ]
    }
   ],
   "source": [
    "ratio_split = RatioSplit(\n",
    "    data=ratings[['UserId', 'ItemId', 'Rating']].values.tolist(),\n",
    "    test_size=0.2,\n",
    "    exclude_unknowns=True,\n",
    "    verbose=True,\n",
    "    seed=12012001,\n",
    "    rating_threshold=0.5,\n",
    "    item_text=item_text_modality,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate DMRL recommender\n",
    "dmrl_recommender = DMRL(\n",
    "    batch_size=4096,\n",
    "    epochs=20,\n",
    "    log_metrics=False,\n",
    "    learning_rate=0.01,\n",
    "    num_factors=2,\n",
    "    decay_r=0.5,\n",
    "    decay_c=0.01,\n",
    "    num_neg=3,\n",
    "    embedding_dim=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DMRL] Training started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/miniconda/envs/sistema_recomendacao_tp2/lib/python3.9/site-packages/cornac/models/dmrl/transformer_text.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_ids = torch.load(id_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-encoding the entire corpus. This might take a while.\n",
      "Using device cuda for training\n",
      "  batch 5 loss: 2839.728076171875\n",
      "  batch 10 loss: 2839.757373046875\n",
      "  batch 15 loss: 2831.77578125\n",
      "  batch 20 loss: 2791.44833984375\n",
      "  batch 25 loss: 2686.66455078125\n",
      "  batch 30 loss: 2593.422119140625\n",
      "  batch 35 loss: 2508.665576171875\n",
      "  batch 40 loss: 2348.50712890625\n",
      "  batch 45 loss: 2184.107275390625\n",
      "  batch 50 loss: 1982.2599853515626\n",
      "  batch 55 loss: 1783.6734619140625\n",
      "  batch 60 loss: 1682.8436767578125\n",
      "  batch 65 loss: 1657.6788330078125\n",
      "  batch 70 loss: 1630.51259765625\n",
      "  batch 75 loss: 1584.9889404296875\n",
      "  batch 80 loss: 1565.05732421875\n",
      "  batch 85 loss: 1569.6202880859375\n",
      "  batch 90 loss: 1541.485791015625\n",
      "  batch 95 loss: 1539.0696533203125\n",
      "  batch 100 loss: 1553.11025390625\n",
      "  batch 105 loss: 1523.523193359375\n",
      "  batch 110 loss: 1503.656591796875\n",
      "  batch 115 loss: 1537.691845703125\n",
      "  batch 120 loss: 1498.9853515625\n",
      "  batch 125 loss: 1510.45986328125\n",
      "Epoch: 0 is done\n",
      "  batch 5 loss: 1361.2318603515625\n",
      "  batch 10 loss: 1355.4750732421876\n",
      "  batch 15 loss: 1347.221337890625\n",
      "  batch 20 loss: 1350.033203125\n",
      "  batch 25 loss: 1349.760693359375\n",
      "  batch 30 loss: 1356.867626953125\n",
      "  batch 35 loss: 1346.1416259765624\n",
      "  batch 40 loss: 1378.2309326171876\n",
      "  batch 45 loss: 1338.5862060546874\n",
      "  batch 50 loss: 1348.309033203125\n",
      "  batch 55 loss: 1343.1658935546875\n",
      "  batch 60 loss: 1321.23427734375\n",
      "  batch 65 loss: 1343.20302734375\n",
      "  batch 70 loss: 1355.5058349609376\n",
      "  batch 75 loss: 1342.5533935546875\n",
      "  batch 80 loss: 1312.6950439453126\n",
      "  batch 85 loss: 1331.446875\n",
      "  batch 90 loss: 1344.56064453125\n",
      "  batch 95 loss: 1313.4568603515625\n",
      "  batch 100 loss: 1324.6692626953125\n",
      "  batch 105 loss: 1310.5451416015626\n",
      "  batch 110 loss: 1309.14794921875\n",
      "  batch 115 loss: 1304.342578125\n",
      "  batch 120 loss: 1306.9948974609374\n",
      "  batch 125 loss: 1320.84267578125\n",
      "Epoch: 1 is done\n",
      "  batch 5 loss: 1158.61025390625\n",
      "  batch 10 loss: 1155.345263671875\n",
      "  batch 15 loss: 1185.62265625\n",
      "  batch 20 loss: 1165.4611328125\n",
      "  batch 25 loss: 1170.793017578125\n",
      "  batch 30 loss: 1172.5131591796876\n",
      "  batch 35 loss: 1168.2478759765625\n",
      "  batch 40 loss: 1173.7267822265626\n",
      "  batch 45 loss: 1190.982177734375\n",
      "  batch 50 loss: 1184.3871826171876\n",
      "  batch 55 loss: 1190.1123046875\n",
      "  batch 60 loss: 1199.288623046875\n",
      "  batch 65 loss: 1196.80126953125\n",
      "  batch 70 loss: 1192.5202880859374\n",
      "  batch 75 loss: 1219.653125\n",
      "  batch 80 loss: 1196.8802490234375\n",
      "  batch 85 loss: 1200.015673828125\n",
      "  batch 90 loss: 1185.75390625\n",
      "  batch 95 loss: 1204.3016357421875\n",
      "  batch 100 loss: 1198.7083251953125\n",
      "  batch 105 loss: 1218.192138671875\n",
      "  batch 110 loss: 1191.9850341796875\n",
      "  batch 115 loss: 1184.908203125\n",
      "  batch 120 loss: 1189.212890625\n",
      "  batch 125 loss: 1229.5092041015625\n",
      "Epoch: 2 is done\n",
      "  batch 5 loss: 1045.821630859375\n",
      "  batch 10 loss: 1048.95361328125\n",
      "  batch 15 loss: 1056.190576171875\n",
      "  batch 20 loss: 1082.77177734375\n",
      "  batch 25 loss: 1082.6276611328126\n",
      "  batch 30 loss: 1097.9509521484374\n",
      "  batch 35 loss: 1106.2579345703125\n",
      "  batch 40 loss: 1106.8926513671875\n",
      "  batch 45 loss: 1095.6508544921876\n",
      "  batch 50 loss: 1092.4957763671875\n",
      "  batch 55 loss: 1104.0240478515625\n",
      "  batch 60 loss: 1098.0115478515625\n",
      "  batch 65 loss: 1127.08017578125\n",
      "  batch 70 loss: 1131.372216796875\n",
      "  batch 75 loss: 1112.8761962890626\n",
      "  batch 80 loss: 1112.3650146484374\n",
      "  batch 85 loss: 1117.187890625\n",
      "  batch 90 loss: 1145.8181396484374\n",
      "  batch 95 loss: 1120.678173828125\n",
      "  batch 100 loss: 1110.9783203125\n",
      "  batch 105 loss: 1132.2150146484375\n",
      "  batch 110 loss: 1134.68740234375\n",
      "  batch 115 loss: 1129.7996337890625\n",
      "  batch 120 loss: 1124.97578125\n",
      "  batch 125 loss: 1125.058642578125\n",
      "Epoch: 3 is done\n",
      "  batch 5 loss: 989.9082763671875\n",
      "  batch 10 loss: 993.1483764648438\n",
      "  batch 15 loss: 1007.0808227539062\n",
      "  batch 20 loss: 1037.98525390625\n",
      "  batch 25 loss: 1043.0814208984375\n",
      "  batch 30 loss: 1043.9478515625\n",
      "  batch 35 loss: 1050.3649169921875\n",
      "  batch 40 loss: 1050.68388671875\n",
      "  batch 45 loss: 1032.8746337890625\n",
      "  batch 50 loss: 1065.267919921875\n",
      "  batch 55 loss: 1050.6353271484375\n",
      "  batch 60 loss: 1062.3487548828125\n",
      "  batch 65 loss: 1069.0240356445313\n",
      "  batch 70 loss: 1083.4395263671875\n",
      "  batch 75 loss: 1101.89921875\n",
      "  batch 80 loss: 1070.715966796875\n",
      "  batch 85 loss: 1080.3336669921875\n",
      "  batch 90 loss: 1086.6648681640625\n",
      "  batch 95 loss: 1094.2168701171875\n",
      "  batch 100 loss: 1103.272216796875\n",
      "  batch 105 loss: 1080.4380126953124\n",
      "  batch 110 loss: 1123.9447265625\n",
      "  batch 115 loss: 1128.7532958984375\n",
      "  batch 120 loss: 1148.7816162109375\n",
      "  batch 125 loss: 1139.696826171875\n",
      "Epoch: 4 is done\n",
      "  batch 5 loss: 952.1652465820313\n",
      "  batch 10 loss: 975.7031372070312\n",
      "  batch 15 loss: 975.3858276367188\n",
      "  batch 20 loss: 998.30712890625\n",
      "  batch 25 loss: 1021.5128173828125\n",
      "  batch 30 loss: 1010.9057373046875\n",
      "  batch 35 loss: 1027.6559936523438\n",
      "  batch 40 loss: 995.6234252929687\n",
      "  batch 45 loss: 1012.1710815429688\n",
      "  batch 50 loss: 1019.8412231445312\n",
      "  batch 55 loss: 1024.73046875\n",
      "  batch 60 loss: 1044.2197265625\n",
      "  batch 65 loss: 1061.5827392578126\n",
      "  batch 70 loss: 1060.5404541015625\n",
      "  batch 75 loss: 1076.907275390625\n",
      "  batch 80 loss: 1065.2562744140625\n",
      "  batch 85 loss: 1087.0373779296874\n",
      "  batch 90 loss: 1066.00205078125\n",
      "  batch 95 loss: 1078.394970703125\n",
      "  batch 100 loss: 1098.8308837890625\n",
      "  batch 105 loss: 1090.29453125\n",
      "  batch 110 loss: 1110.0998291015626\n",
      "  batch 115 loss: 1113.3314697265625\n",
      "  batch 120 loss: 1093.1426025390624\n",
      "  batch 125 loss: 1123.416845703125\n",
      "Epoch: 5 is done\n",
      "  batch 5 loss: 947.1553588867188\n",
      "  batch 10 loss: 976.7884765625\n",
      "  batch 15 loss: 990.0467651367187\n",
      "  batch 20 loss: 964.84619140625\n",
      "  batch 25 loss: 976.834814453125\n",
      "  batch 30 loss: 985.5394653320312\n",
      "  batch 35 loss: 1031.7961791992188\n",
      "  batch 40 loss: 1012.8330200195312\n",
      "  batch 45 loss: 1019.9621826171875\n",
      "  batch 50 loss: 1022.4747924804688\n",
      "  batch 55 loss: 1029.9739624023437\n",
      "  batch 60 loss: 1046.1827514648437\n",
      "  batch 65 loss: 1050.8662353515624\n",
      "  batch 70 loss: 1067.4620361328125\n",
      "  batch 75 loss: 1069.4297119140624\n",
      "  batch 80 loss: 1039.5866333007812\n",
      "  batch 85 loss: 1059.6892578125\n",
      "  batch 90 loss: 1076.66328125\n",
      "  batch 95 loss: 1091.7381103515625\n",
      "  batch 100 loss: 1077.3114990234376\n",
      "  batch 105 loss: 1070.066552734375\n",
      "  batch 110 loss: 1091.8178466796876\n",
      "  batch 115 loss: 1110.1679931640624\n",
      "  batch 120 loss: 1071.21689453125\n",
      "  batch 125 loss: 1114.028857421875\n",
      "Epoch: 6 is done\n",
      "  batch 5 loss: 933.857177734375\n",
      "  batch 10 loss: 948.2892578125\n",
      "  batch 15 loss: 983.8521728515625\n",
      "  batch 20 loss: 978.2920532226562\n",
      "  batch 25 loss: 975.1590454101563\n",
      "  batch 30 loss: 1004.4525512695312\n",
      "  batch 35 loss: 982.7611938476563\n",
      "  batch 40 loss: 999.9318725585938\n",
      "  batch 45 loss: 1000.5931884765625\n",
      "  batch 50 loss: 1029.7032470703125\n",
      "  batch 55 loss: 1029.5977294921875\n",
      "  batch 60 loss: 1053.0918212890624\n",
      "  batch 65 loss: 1043.9408203125\n",
      "  batch 70 loss: 1046.8887939453125\n",
      "  batch 75 loss: 1033.066748046875\n",
      "  batch 80 loss: 1058.0431396484375\n",
      "  batch 85 loss: 1053.465625\n",
      "  batch 90 loss: 1053.0897827148438\n",
      "  batch 95 loss: 1077.6748779296875\n",
      "  batch 100 loss: 1061.087451171875\n",
      "  batch 105 loss: 1092.8514892578125\n",
      "  batch 110 loss: 1095.49892578125\n",
      "  batch 115 loss: 1091.9037109375\n",
      "  batch 120 loss: 1094.787109375\n",
      "  batch 125 loss: 1096.7458740234374\n",
      "Epoch: 7 is done\n",
      "  batch 5 loss: 942.0486938476563\n",
      "  batch 10 loss: 945.751806640625\n",
      "  batch 15 loss: 972.6380615234375\n",
      "  batch 20 loss: 995.3343627929687\n",
      "  batch 25 loss: 981.73603515625\n",
      "  batch 30 loss: 1006.7013549804688\n",
      "  batch 35 loss: 979.4141723632813\n",
      "  batch 40 loss: 999.2052612304688\n",
      "  batch 45 loss: 991.5373657226562\n",
      "  batch 50 loss: 1021.4609985351562\n",
      "  batch 55 loss: 1018.856982421875\n",
      "  batch 60 loss: 1030.835595703125\n",
      "  batch 65 loss: 1048.9676025390625\n",
      "  batch 70 loss: 1036.2085693359375\n",
      "  batch 75 loss: 1070.967333984375\n",
      "  batch 80 loss: 1040.2847900390625\n",
      "  batch 85 loss: 1054.5198974609375\n",
      "  batch 90 loss: 1060.0474853515625\n",
      "  batch 95 loss: 1068.060546875\n",
      "  batch 100 loss: 1078.5731201171875\n",
      "  batch 105 loss: 1057.2905517578124\n",
      "  batch 110 loss: 1085.3489990234375\n",
      "  batch 115 loss: 1095.534326171875\n",
      "  batch 120 loss: 1083.8919677734375\n",
      "  batch 125 loss: 1115.5893798828124\n",
      "Epoch: 8 is done\n",
      "  batch 5 loss: 937.184033203125\n",
      "  batch 10 loss: 959.9252563476563\n",
      "  batch 15 loss: 953.1740600585938\n",
      "  batch 20 loss: 978.4556030273437\n",
      "  batch 25 loss: 980.7909790039063\n",
      "  batch 30 loss: 986.8568481445312\n",
      "  batch 35 loss: 1008.2974975585937\n",
      "  batch 40 loss: 989.5412353515625\n",
      "  batch 45 loss: 1004.5407958984375\n",
      "  batch 50 loss: 1027.4855224609375\n",
      "  batch 55 loss: 1037.4950439453125\n",
      "  batch 60 loss: 1022.3750732421875\n",
      "  batch 65 loss: 1025.9146850585937\n",
      "  batch 70 loss: 1061.728076171875\n",
      "  batch 75 loss: 1057.2424194335938\n",
      "  batch 80 loss: 1058.7549560546875\n",
      "  batch 85 loss: 1052.227685546875\n",
      "  batch 90 loss: 1048.541064453125\n",
      "  batch 95 loss: 1070.2353515625\n",
      "  batch 100 loss: 1099.8921875\n",
      "  batch 105 loss: 1078.0897705078125\n",
      "  batch 110 loss: 1077.515673828125\n",
      "  batch 115 loss: 1092.305615234375\n",
      "  batch 120 loss: 1075.5657470703125\n",
      "  batch 125 loss: 1104.568994140625\n",
      "Epoch: 9 is done\n",
      "  batch 5 loss: 947.457080078125\n",
      "  batch 10 loss: 964.7966674804687\n",
      "  batch 15 loss: 968.3059204101562\n",
      "  batch 20 loss: 959.017578125\n",
      "  batch 25 loss: 952.8630615234375\n",
      "  batch 30 loss: 978.1044311523438\n",
      "  batch 35 loss: 998.8496826171875\n",
      "  batch 40 loss: 1014.840087890625\n",
      "  batch 45 loss: 1009.6217529296875\n",
      "  batch 50 loss: 1011.278173828125\n",
      "  batch 55 loss: 1020.7598876953125\n",
      "  batch 60 loss: 1027.516357421875\n",
      "  batch 65 loss: 1014.8805053710937\n",
      "  batch 70 loss: 1027.6234008789063\n",
      "  batch 75 loss: 1051.375244140625\n",
      "  batch 80 loss: 1081.4794677734376\n",
      "  batch 85 loss: 1081.295263671875\n",
      "  batch 90 loss: 1050.9883056640624\n",
      "  batch 95 loss: 1082.049951171875\n",
      "  batch 100 loss: 1086.50771484375\n",
      "  batch 105 loss: 1080.8124877929688\n",
      "  batch 110 loss: 1072.9319091796874\n",
      "  batch 115 loss: 1100.415234375\n",
      "  batch 120 loss: 1089.4780029296876\n",
      "  batch 125 loss: 1078.9821899414062\n",
      "Epoch: 10 is done\n",
      "  batch 5 loss: 938.7539428710937\n",
      "  batch 10 loss: 966.8247680664062\n",
      "  batch 15 loss: 924.8107299804688\n",
      "  batch 20 loss: 982.5482421875\n",
      "  batch 25 loss: 1004.133544921875\n",
      "  batch 30 loss: 989.111572265625\n",
      "  batch 35 loss: 998.7968627929688\n",
      "  batch 40 loss: 1014.8395263671875\n",
      "  batch 45 loss: 1012.1991577148438\n",
      "  batch 50 loss: 1033.97939453125\n",
      "  batch 55 loss: 1006.800390625\n",
      "  batch 60 loss: 1046.29873046875\n",
      "  batch 65 loss: 1035.38701171875\n",
      "  batch 70 loss: 1047.5883544921876\n",
      "  batch 75 loss: 1046.4475952148437\n",
      "  batch 80 loss: 1069.3974853515624\n",
      "  batch 85 loss: 1052.2897338867188\n",
      "  batch 90 loss: 1060.6491088867188\n",
      "  batch 95 loss: 1052.607373046875\n",
      "  batch 100 loss: 1069.46484375\n",
      "  batch 105 loss: 1070.987646484375\n",
      "  batch 110 loss: 1111.9674560546875\n",
      "  batch 115 loss: 1108.2306884765626\n",
      "  batch 120 loss: 1073.529736328125\n",
      "  batch 125 loss: 1104.036669921875\n",
      "Epoch: 11 is done\n",
      "  batch 5 loss: 945.3448852539062\n",
      "  batch 10 loss: 952.467919921875\n",
      "  batch 15 loss: 959.8256591796875\n",
      "  batch 20 loss: 971.7848754882813\n",
      "  batch 25 loss: 1003.298291015625\n",
      "  batch 30 loss: 975.1162231445312\n",
      "  batch 35 loss: 1011.2479370117187\n",
      "  batch 40 loss: 986.9811889648438\n",
      "  batch 45 loss: 1014.4859130859375\n",
      "  batch 50 loss: 1017.7563232421875\n",
      "  batch 55 loss: 1028.73310546875\n",
      "  batch 60 loss: 1033.1019287109375\n",
      "  batch 65 loss: 1038.4771118164062\n",
      "  batch 70 loss: 1039.5748901367188\n",
      "  batch 75 loss: 1058.6404541015625\n",
      "  batch 80 loss: 1027.4658203125\n",
      "  batch 85 loss: 1058.8892211914062\n",
      "  batch 90 loss: 1048.0361938476562\n",
      "  batch 95 loss: 1067.0998291015626\n",
      "  batch 100 loss: 1063.8871826171876\n",
      "  batch 105 loss: 1092.5528564453125\n",
      "  batch 110 loss: 1078.8928466796874\n",
      "  batch 115 loss: 1074.9634033203124\n",
      "  batch 120 loss: 1094.9373046875\n",
      "  batch 125 loss: 1100.4348388671874\n",
      "Epoch: 12 is done\n",
      "  batch 5 loss: 947.746337890625\n",
      "  batch 10 loss: 948.2227294921875\n",
      "  batch 15 loss: 966.80048828125\n",
      "  batch 20 loss: 955.659130859375\n",
      "  batch 25 loss: 993.4601928710938\n",
      "  batch 30 loss: 986.789501953125\n",
      "  batch 35 loss: 1004.7273681640625\n",
      "  batch 40 loss: 985.4245239257813\n",
      "  batch 45 loss: 997.8472290039062\n",
      "  batch 50 loss: 1020.0221313476562\n",
      "  batch 55 loss: 1030.9058471679687\n",
      "  batch 60 loss: 1025.3263793945312\n",
      "  batch 65 loss: 1016.5661743164062\n",
      "  batch 70 loss: 1028.3792114257812\n",
      "  batch 75 loss: 1036.2115478515625\n",
      "  batch 80 loss: 1056.486083984375\n",
      "  batch 85 loss: 1081.70458984375\n",
      "  batch 90 loss: 1074.86953125\n",
      "  batch 95 loss: 1084.85673828125\n",
      "  batch 100 loss: 1076.6229248046875\n",
      "  batch 105 loss: 1102.033447265625\n",
      "  batch 110 loss: 1109.0418701171875\n",
      "  batch 115 loss: 1077.0193115234374\n",
      "  batch 120 loss: 1083.87001953125\n",
      "  batch 125 loss: 1098.981103515625\n",
      "Epoch: 13 is done\n",
      "  batch 5 loss: 951.2488647460938\n",
      "  batch 10 loss: 928.0408325195312\n",
      "  batch 15 loss: 988.7479125976563\n",
      "  batch 20 loss: 972.569970703125\n",
      "  batch 25 loss: 976.2492309570313\n",
      "  batch 30 loss: 1005.3493774414062\n",
      "  batch 35 loss: 988.1052734375\n",
      "  batch 40 loss: 984.9530639648438\n",
      "  batch 45 loss: 1003.9906372070312\n",
      "  batch 50 loss: 1016.0487060546875\n",
      "  batch 55 loss: 989.9975219726563\n",
      "  batch 60 loss: 1061.0388916015625\n",
      "  batch 65 loss: 1030.9759033203125\n",
      "  batch 70 loss: 1046.8501220703124\n",
      "  batch 75 loss: 1051.9005249023437\n",
      "  batch 80 loss: 1040.4766967773437\n",
      "  batch 85 loss: 1082.3424560546875\n",
      "  batch 90 loss: 1070.8225341796874\n",
      "  batch 95 loss: 1055.99443359375\n",
      "  batch 100 loss: 1088.2126953125\n",
      "  batch 105 loss: 1086.82353515625\n",
      "  batch 110 loss: 1098.2309814453124\n",
      "  batch 115 loss: 1103.370654296875\n",
      "  batch 120 loss: 1081.7984619140625\n",
      "  batch 125 loss: 1095.211962890625\n",
      "Epoch: 14 is done\n",
      "  batch 5 loss: 939.5514770507813\n",
      "  batch 10 loss: 962.8492431640625\n",
      "  batch 15 loss: 950.0901000976562\n",
      "  batch 20 loss: 973.7994750976562\n",
      "  batch 25 loss: 986.4316284179688\n",
      "  batch 30 loss: 992.38974609375\n",
      "  batch 35 loss: 988.9254516601562\n",
      "  batch 40 loss: 1006.1927001953125\n",
      "  batch 45 loss: 1017.6041381835937\n",
      "  batch 50 loss: 991.7502319335938\n",
      "  batch 55 loss: 1021.9746459960937\n",
      "  batch 60 loss: 1045.8888427734375\n",
      "  batch 65 loss: 1016.9393432617187\n",
      "  batch 70 loss: 1067.692529296875\n",
      "  batch 75 loss: 1045.481201171875\n",
      "  batch 80 loss: 1092.731982421875\n",
      "  batch 85 loss: 1063.0456298828126\n",
      "  batch 90 loss: 1054.2658447265626\n",
      "  batch 95 loss: 1098.0193603515625\n",
      "  batch 100 loss: 1074.83310546875\n",
      "  batch 105 loss: 1078.95400390625\n",
      "  batch 110 loss: 1099.245166015625\n",
      "  batch 115 loss: 1083.742626953125\n",
      "  batch 120 loss: 1077.8957763671874\n",
      "  batch 125 loss: 1075.0301513671875\n",
      "Epoch: 15 is done\n",
      "  batch 5 loss: 939.6281860351562\n",
      "  batch 10 loss: 925.1663818359375\n",
      "  batch 15 loss: 963.3898071289062\n",
      "  batch 20 loss: 952.7489135742187\n",
      "  batch 25 loss: 962.1620361328125\n",
      "  batch 30 loss: 974.5912353515625\n",
      "  batch 35 loss: 990.8175415039062\n",
      "  batch 40 loss: 1010.179443359375\n",
      "  batch 45 loss: 994.8233764648437\n",
      "  batch 50 loss: 1007.3614013671875\n",
      "  batch 55 loss: 1025.0954833984374\n",
      "  batch 60 loss: 1044.8892333984375\n",
      "  batch 65 loss: 1074.1015380859376\n",
      "  batch 70 loss: 1038.9129150390625\n",
      "  batch 75 loss: 1054.837158203125\n",
      "  batch 80 loss: 1060.601416015625\n",
      "  batch 85 loss: 1045.1390380859375\n",
      "  batch 90 loss: 1091.8474365234374\n",
      "  batch 95 loss: 1063.23720703125\n",
      "  batch 100 loss: 1069.198681640625\n",
      "  batch 105 loss: 1070.416552734375\n",
      "  batch 110 loss: 1074.156201171875\n",
      "  batch 115 loss: 1087.5893798828124\n",
      "  batch 120 loss: 1079.9115966796876\n",
      "  batch 125 loss: 1084.4554443359375\n",
      "Epoch: 16 is done\n",
      "  batch 5 loss: 933.0762451171875\n",
      "  batch 10 loss: 966.5688842773437\n",
      "  batch 15 loss: 954.5393432617187\n",
      "  batch 20 loss: 957.1583129882813\n",
      "  batch 25 loss: 986.2091186523437\n",
      "  batch 30 loss: 987.7428833007813\n",
      "  batch 35 loss: 1003.9339477539063\n",
      "  batch 40 loss: 994.4178344726563\n",
      "  batch 45 loss: 986.5000732421875\n",
      "  batch 50 loss: 1041.2236083984376\n",
      "  batch 55 loss: 1042.25732421875\n",
      "  batch 60 loss: 1007.6460083007812\n",
      "  batch 65 loss: 1032.7774536132813\n",
      "  batch 70 loss: 1031.1081298828126\n",
      "  batch 75 loss: 1034.603515625\n",
      "  batch 80 loss: 1071.1261962890626\n",
      "  batch 85 loss: 1048.7481201171875\n",
      "  batch 90 loss: 1052.5776245117188\n",
      "  batch 95 loss: 1054.7801513671875\n",
      "  batch 100 loss: 1091.8796142578126\n",
      "  batch 105 loss: 1081.8426513671875\n",
      "  batch 110 loss: 1077.53935546875\n",
      "  batch 115 loss: 1101.332958984375\n",
      "  batch 120 loss: 1104.6894287109376\n",
      "  batch 125 loss: 1116.662548828125\n",
      "Epoch: 17 is done\n",
      "  batch 5 loss: 914.9986206054688\n",
      "  batch 10 loss: 953.3117797851562\n",
      "  batch 15 loss: 952.4857177734375\n",
      "  batch 20 loss: 949.890087890625\n",
      "  batch 25 loss: 989.7651611328125\n",
      "  batch 30 loss: 1004.581689453125\n",
      "  batch 35 loss: 998.6606689453125\n",
      "  batch 40 loss: 986.4217529296875\n",
      "  batch 45 loss: 1016.0768798828125\n",
      "  batch 50 loss: 1020.9642944335938\n",
      "  batch 55 loss: 1013.4348388671875\n",
      "  batch 60 loss: 1029.5038818359376\n",
      "  batch 65 loss: 1039.772412109375\n",
      "  batch 70 loss: 1051.2033935546874\n",
      "  batch 75 loss: 1048.5461181640626\n",
      "  batch 80 loss: 1058.3566162109375\n",
      "  batch 85 loss: 1058.5829345703125\n",
      "  batch 90 loss: 1055.8069091796874\n",
      "  batch 95 loss: 1068.42763671875\n",
      "  batch 100 loss: 1082.6215087890625\n",
      "  batch 105 loss: 1092.7853759765626\n",
      "  batch 110 loss: 1095.7533203125\n",
      "  batch 115 loss: 1069.212939453125\n",
      "  batch 120 loss: 1088.3503662109374\n",
      "  batch 125 loss: 1088.1715087890625\n",
      "Epoch: 18 is done\n",
      "  batch 5 loss: 933.8757934570312\n",
      "  batch 10 loss: 941.4007446289063\n",
      "  batch 15 loss: 952.6801635742188\n",
      "  batch 20 loss: 937.2211547851563\n",
      "  batch 25 loss: 996.3117309570313\n",
      "  batch 30 loss: 977.3108032226562\n",
      "  batch 35 loss: 979.3007446289063\n",
      "  batch 40 loss: 1018.576953125\n",
      "  batch 45 loss: 1000.9416381835938\n",
      "  batch 50 loss: 1028.2690307617188\n",
      "  batch 55 loss: 1021.72314453125\n",
      "  batch 60 loss: 1018.6294799804688\n",
      "  batch 65 loss: 1051.0743408203125\n",
      "  batch 70 loss: 1038.1114868164063\n",
      "  batch 75 loss: 1028.2916137695313\n",
      "  batch 80 loss: 1070.9203369140625\n",
      "  batch 85 loss: 1054.6302978515625\n",
      "  batch 90 loss: 1058.052978515625\n",
      "  batch 95 loss: 1084.7892822265626\n",
      "  batch 100 loss: 1072.3960693359375\n",
      "  batch 105 loss: 1095.97451171875\n",
      "  batch 110 loss: 1108.0641845703126\n",
      "  batch 115 loss: 1087.08583984375\n",
      "  batch 120 loss: 1110.2065673828124\n",
      "  batch 125 loss: 1084.323486328125\n",
      "Epoch: 19 is done\n",
      "Finished training!\n",
      "\n",
      "[DMRL] Evaluation started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking: 100%|██████████| 19975/19975 [05:23<00:00, 61.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "     | NDCG@-1 | Train (s) | Test (s)\n",
      "---- + ------- + --------- + --------\n",
      "DMRL |  0.2387 |  126.9726 | 323.7108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Put everything together into an experiment and run it\n",
    "cornac.Experiment(\n",
    "    eval_method=ratio_split, models=[dmrl_recommender], metrics=[NDCG()]\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como usar esse algoritmo para tratar itens novos?\n",
    "# # como usar esse algoritmo para tratar usuarios novos?\n",
    "\n",
    "\n",
    "# eu tenho o conteudo de todos os itens, incluive itens que estao apenas n conjunto de teste?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 02b780c583 is not in the train set\n",
      "User 03fbe3c1e8 is not in the train set\n",
      "User 0503bf6097 is not in the train set\n",
      "User 0958560bd4 is not in the train set\n",
      "User 0b17c3df40 is not in the train set\n",
      "User 10c3aef33f is not in the train set\n",
      "User 119653373a is not in the train set\n",
      "User 139ccdbf5a is not in the train set\n",
      "User 1671fa4df3 is not in the train set\n",
      "User 16757f4d90 is not in the train set\n",
      "User 187454feb4 is not in the train set\n",
      "User 1af811e7b9 is not in the train set\n",
      "User 1bbf59e4a4 is not in the train set\n",
      "User 1ef563bb8b is not in the train set\n",
      "User 1f6a565547 is not in the train set\n",
      "User 211a7a84d3 is not in the train set\n",
      "User 243be2818a is not in the train set\n",
      "User 24a13b72fc is not in the train set\n",
      "User 27649dc46e is not in the train set\n",
      "User 2a3500f75b is not in the train set\n",
      "User 2ae6906d5d is not in the train set\n",
      "User 2cfdb14e05 is not in the train set\n",
      "User 2ed4d0c23c is not in the train set\n",
      "User 2ef13886ae is not in the train set\n",
      "User 302c6ebc7d is not in the train set\n",
      "User 3174db8344 is not in the train set\n",
      "User 32806098d9 is not in the train set\n",
      "User 33f009eb84 is not in the train set\n",
      "User 3402dfd220 is not in the train set\n",
      "User 35ecd9a245 is not in the train set\n",
      "User 3bf47241fd is not in the train set\n",
      "User 3cdc0a294d is not in the train set\n",
      "User 3f332c6d51 is not in the train set\n",
      "User 40008b9a53 is not in the train set\n",
      "User 40bf82623c is not in the train set\n",
      "User 4152564eeb is not in the train set\n",
      "User 448cd8ad0a is not in the train set\n",
      "User 454ea70f2b is not in the train set\n",
      "User 4579da10f3 is not in the train set\n",
      "User 49e73b2050 is not in the train set\n",
      "User 4a125a89bf is not in the train set\n",
      "User 4ad5bd1af9 is not in the train set\n",
      "User 4aec1b3435 is not in the train set\n",
      "User 4c0f9546c5 is not in the train set\n",
      "User 4c964a55e0 is not in the train set\n",
      "User 4e701bcd4c is not in the train set\n",
      "User 50a40208ac is not in the train set\n",
      "User 51aa0a41c5 is not in the train set\n",
      "User 51e0fff3f3 is not in the train set\n",
      "User 51f4efbfb3 is not in the train set\n",
      "User 52a8ed6a81 is not in the train set\n",
      "User 53d6d0c034 is not in the train set\n",
      "User 548b57cc0f is not in the train set\n",
      "User 564ed2dbdd is not in the train set\n",
      "User 621eb0b827 is not in the train set\n",
      "User 64bb3c7589 is not in the train set\n",
      "User 65d03e7a8e is not in the train set\n",
      "User 676c6ba546 is not in the train set\n",
      "User 689b243e8f is not in the train set\n",
      "User 69f65a2e91 is not in the train set\n",
      "User 6b620aedfa is not in the train set\n",
      "User 6c2665d7c3 is not in the train set\n",
      "User 6ec3ff0c92 is not in the train set\n",
      "User 70b0e5c6b6 is not in the train set\n",
      "User 71887f62f0 is not in the train set\n",
      "User 790d67b8e3 is not in the train set\n",
      "User 7c9ff93b39 is not in the train set\n",
      "User 7cef9fb420 is not in the train set\n",
      "User 7d5606f152 is not in the train set\n",
      "User 82ccad1ecc is not in the train set\n",
      "User 84550b83da is not in the train set\n",
      "User 8487e01fba is not in the train set\n",
      "User 848ceaa463 is not in the train set\n",
      "User 84a955d5ff is not in the train set\n",
      "User 84c230a5b1 is not in the train set\n",
      "User 86f2df8b1f is not in the train set\n",
      "User 87f3c42a65 is not in the train set\n",
      "User 8b2b3227d4 is not in the train set\n",
      "User 8c5a6a7482 is not in the train set\n",
      "User 8d2355364e is not in the train set\n",
      "User 8deddf03f0 is not in the train set\n",
      "User 8f1fbc45b8 is not in the train set\n",
      "User 8fc809ece3 is not in the train set\n",
      "User 8ff4a061e9 is not in the train set\n",
      "User 93c442d40a is not in the train set\n",
      "User 9424d06c85 is not in the train set\n",
      "User 943422623d is not in the train set\n",
      "User 964e752094 is not in the train set\n",
      "User 9752ba9f1e is not in the train set\n",
      "User 997d421097 is not in the train set\n",
      "User 9b03bd15cd is not in the train set\n",
      "User 9c415bdd4d is not in the train set\n",
      "User 9c810c5750 is not in the train set\n",
      "User a13e00b085 is not in the train set\n",
      "User a559244ec4 is not in the train set\n",
      "User acd6425f2d is not in the train set\n",
      "User acf73df8e4 is not in the train set\n",
      "User ad17a667ff is not in the train set\n",
      "User ad52498830 is not in the train set\n",
      "User adeaee4e38 is not in the train set\n",
      "User ae845eb437 is not in the train set\n",
      "User af4d3ce5d7 is not in the train set\n",
      "User b0e7534770 is not in the train set\n",
      "User b6ef5d5380 is not in the train set\n",
      "User b9898a075a is not in the train set\n",
      "User baa84d7484 is not in the train set\n",
      "User bb07992b31 is not in the train set\n",
      "User bbc77a1cfa is not in the train set\n",
      "User bdbe7e66f5 is not in the train set\n",
      "User be800ff41f is not in the train set\n",
      "User c14cc363e3 is not in the train set\n",
      "User c29b3351dd is not in the train set\n",
      "User c4f7cfb1e9 is not in the train set\n",
      "User c846afeb97 is not in the train set\n",
      "User c9b7db2d84 is not in the train set\n",
      "User cb955adc83 is not in the train set\n",
      "User cd13636b75 is not in the train set\n",
      "User cdd9c13725 is not in the train set\n",
      "User cf247d6daf is not in the train set\n",
      "User d1e7b08bdb is not in the train set\n",
      "User d29ee932b7 is not in the train set\n",
      "User d38901788c is not in the train set\n",
      "User d3956e2280 is not in the train set\n",
      "User d481fbe55e is not in the train set\n",
      "User d5cb15b7ec is not in the train set\n",
      "User d5e542d0cb is not in the train set\n",
      "User d606046667 is not in the train set\n",
      "User d9e6b46563 is not in the train set\n",
      "User daf33743af is not in the train set\n",
      "User db081d0be2 is not in the train set\n",
      "User db9d463dc9 is not in the train set\n",
      "User dc09c97fd7 is not in the train set\n",
      "User dcfd532698 is not in the train set\n",
      "User dd669b686f is not in the train set\n",
      "User def80cfcb4 is not in the train set\n",
      "User e321abd135 is not in the train set\n",
      "User e33bff0ce0 is not in the train set\n",
      "User e449b9317d is not in the train set\n",
      "User e480783401 is not in the train set\n",
      "User e9405e0733 is not in the train set\n",
      "User ea4b47f29f is not in the train set\n",
      "User ee16fa83c0 is not in the train set\n",
      "User ee6e910d8a is not in the train set\n",
      "User f0897e959b is not in the train set\n",
      "User f28f881458 is not in the train set\n",
      "User f4573fc71c is not in the train set\n",
      "User f7bf6074f6 is not in the train set\n",
      "User f8ea2e8463 is not in the train set\n",
      "User f9db6a7cd6 is not in the train set\n",
      "User fa07516b1d is not in the train set\n",
      "User fa2093fecd is not in the train set\n",
      "User fb2e203234 is not in the train set\n",
      "User fbe486dc4c is not in the train set\n",
      "User fc1aaf2d2e is not in the train set\n",
      "User fc1dc4549d is not in the train set\n",
      "User fdacbbcc2e is not in the train set\n",
      "User fe9de77866 is not in the train set\n",
      "User ff5552bd9e is not in the train set\n",
      "User ffbad8b9da is not in the train set\n"
     ]
    }
   ],
   "source": [
    "target_prediction = targets.copy()\n",
    "target_prediction[\"Rating\"] = -1\n",
    "\n",
    "user_id_list = targets.UserId.unique()\n",
    "for user_id in user_id_list:\n",
    "    # Get the train dataframe index of the user to predict\n",
    "    user_index = ratio_split.train_set.uid_map.get(user_id)\n",
    "\n",
    "    if user_index is None:\n",
    "        print(f\"User {user_id} is not in the train set\")\n",
    "        continue\n",
    "\n",
    "    # Flter by items to predict \n",
    "    items_to_predict = targets.loc[targets.UserId == user_id, \"ItemId\"].to_list()\n",
    "\n",
    "    # Get the train dataframe index of the items to predict\n",
    "    items_to_predict_index = np.array([ratio_split.train_set.iid_map.get(item_id) for item_id in items_to_predict])\n",
    "\n",
    "    items_to_predict_tensor = torch.tensor([idx for idx in items_to_predict_index if idx is not None])\n",
    "\n",
    "    # Get the position of items that are not in the train set\n",
    "    none_indices = [i for i, x in enumerate(items_to_predict_index) if x is None]\n",
    "\n",
    "    # Get the prediction for the items\n",
    "    line_rating = dmrl_recommender.score(user_index=user_index, item_indices=items_to_predict_tensor)\n",
    "\n",
    "    # Insert -1 in the position of items that are not in the train set\n",
    "    for index_to_insert in none_indices:\n",
    "        line_rating = np.insert(line_rating, index_to_insert, -1)\n",
    "\n",
    "    # Insert the prediction in the target_prediction dataframe\n",
    "    target_prediction.loc[targets.UserId == user_id, \"Rating\"] = line_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction = target_prediction.sort_values([\"UserId\", \"Rating\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction.to_csv(\"submissao_3_DMRL_versao_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction = target_prediction.drop(columns=\"Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction.to_csv(\"submissao_3_DMRL_versao_2_sem_rating.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sistema_recomendacao_tp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
