{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# based-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideias:\n",
    "- FEITO: Usar a coluna para no texto\n",
    "- FEITO: Limpar os dados de conteudo\n",
    "- FEITO (lucas): ordenar os itens novos que ficaram por ultimo por popularidade\n",
    "- FEITO: Adicionar o nome da coluna, porque vai indicar o assunto, em conjunto do texto\n",
    "\n",
    "- tunar os hiperparametros\n",
    "- usa a imagem alem do texto\n",
    "- usar algum algoritmo mais simples apenas para usuarios novos, knn para content based\n",
    "- Entender o parametro exclude_unknowns=True do RatioSplit e se tem alguma forma do DMRL gerar previsoes para itens e usuarios novos \n",
    "\n",
    "- paralelizar a previsao\n",
    "Perguntas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils import load_data\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, content, targets = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"TimestampDate\"] = ratings['Timestamp'].dt.date\n",
    "ratings.loc[ratings.Rating == 0, \"Rating\"] = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpar os dados de conteudo\n",
    "\n",
    "- FEITO - Year: deletar o - no texto '2013–'\n",
    "- FEITO - Rated: alterar as diversas formas de escrever NA para NA. Esse e um caso especial\n",
    "- FEITO - alterar as diversas formas de escrever NA para None em todas as coluans\n",
    "- FEITO - Language: tem varias linhas que possuem bizarices como  'None, English' e 'None, French' , 'English, None'...\n",
    "- FEITO - Ratings: criar uma coluna para cada chave do dicionario, entender quais sao todas as chaves que existem\n",
    "\n",
    "-----------------------------------------------\n",
    "Variaveis que nao precisariam ser tratadas com um bert:\n",
    "- Metascore\n",
    "- imdbRating\n",
    "- Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar = content.drop(columns=[\"Poster\", \"Website\", \"Response\", \"Episode\", \"seriesID\", \"Season\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar['Year'] = content_auxiliar['Year'].str.replace('–', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = content.totalSeasons.unique()[0]\n",
    "dict_transform_to_na = {\n",
    "    \"Rated\":['N/A', 'Not Rated', 'Unrated', 'UNRATED', 'NOT RATED'],\n",
    "    \"all\": [nan, 'N/A', 'None', np.nan],\n",
    "}\n",
    "\n",
    "for na_value in dict_transform_to_na[\"all\"]:\n",
    "    content_auxiliar = content_auxiliar.replace(na_value, None)\n",
    "\n",
    "for na_value in dict_transform_to_na[\"Rated\"]:\n",
    "    content_auxiliar['Rated'] = content_auxiliar['Rated'].replace(na_value, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar['Language'] = content_auxiliar['Language'].str.replace('None, ', '')\n",
    "content_auxiliar['Language'] = content_auxiliar['Language'].str.replace(', None', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Internet Movie Database', 'Metacritic', 'Rotten Tomatoes'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entendendo os valores possiveis para a coluna Ratings\n",
    "# A coluna content_auxiliar.Ratings quarda uma lista que posde ter entre 0 e 3 dicionarios. Cada dicionario possui a chave 'Source', 'Value'.\n",
    "num_ratings_per_item = []\n",
    "unique_keys = []\n",
    "rating_sources = []\n",
    "rating_values = []\n",
    "\n",
    "for rating_list in content_auxiliar.Ratings:\n",
    "    num_ratings_per_item.append(len(rating_list))\n",
    "    for rating_dict in rating_list:\n",
    "        for key in rating_dict:\n",
    "            unique_keys.append(key)\n",
    "        rating_sources.append(rating_dict['Source'])\n",
    "        rating_values.append(rating_dict['Value'])\n",
    "\n",
    "set(rating_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "InternetMovieDatabase_list = []\n",
    "Metacritic_list = []\n",
    "RottenTomatoes_list = []\n",
    "for rating_list in content_auxiliar.Ratings:\n",
    "    InternetMovieDatabase_list.append(None)\n",
    "    Metacritic_list.append(None)\n",
    "    RottenTomatoes_list.append(None)\n",
    "    for rating_dict in rating_list:\n",
    "        if rating_dict['Source'] == 'Internet Movie Database':\n",
    "            InternetMovieDatabase_list[-1] = rating_dict['Value']\n",
    "        elif rating_dict['Source'] == 'Metacritic':\n",
    "            Metacritic_list[-1] = rating_dict['Value']\n",
    "        elif rating_dict['Source'] == 'Rotten Tomatoes':\n",
    "            RottenTomatoes_list[-1] = rating_dict['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar['Internet Movie Database'] = InternetMovieDatabase_list\n",
    "content_auxiliar['Metacritic'] = Metacritic_list\n",
    "content_auxiliar['Rotten Tomatoes'] = RottenTomatoes_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar.drop(columns=['Ratings'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apendar a coluna no valor do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_columns = content_auxiliar.columns.to_list()\n",
    "# content_columns.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in content_columns:\n",
    "#     content_auxiliar[column] = content_auxiliar[column].apply(lambda x: f\"{column}: {x}; \" if x is not None else f\"{column}: unknown value; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_processed = content_auxiliar[['ItemId']].copy()\n",
    "# content_processed[\"text\"] = content_auxiliar[content_columns].astype(str).fillna('').agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viabiliza as colunas para um modelo tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar[\"Internet Movie Database\"] = content_auxiliar[\"Internet Movie Database\"].str.split(\"/\").apply(lambda x: x[0] if x is not None else None)\n",
    "content_auxiliar[\"Rotten Tomatoes\"].replace('%', \"\", regex=True, inplace=True)\n",
    "content_auxiliar[\"Metacritic\"].replace('/100', \"\", regex=True, inplace=True)\n",
    "content_auxiliar[\"imdbVotes\"].replace(',', \"\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar[\"BoxOffice\"].replace(',', \"\", regex=True, inplace=True)\n",
    "\n",
    "# O metodo replace nao funcionnou para $, cuidado para nao rodar essa cedula 2 vezes\n",
    "content_auxiliar[\"BoxOffice\"] = content_auxiliar[\"BoxOffice\"].apply(lambda x: x[1:] if x is not None else None) # troca valores $ por \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar[\"Runtime\"].replace(' min', \"\", regex=True, inplace=True)\n",
    "mask = content_auxiliar.Runtime.str.contains('h', na=False)\n",
    "content_auxiliar.loc[mask, \"Runtime\"] = content_auxiliar.loc[mask, \"Runtime\"].str.split(\"h\").apply(lambda x: str(int(x[0]) * 60 + int(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_float = ['Runtime', 'Internet Movie Database', 'Metacritic',\n",
    "                    'Rotten Tomatoes', \"imdbVotes\", \"BoxOffice\",\n",
    "                    \"totalSeasons\", \"imdbRating\", \"Metascore\"]  # Falta tartar Awards\n",
    "content_auxiliar[columns_to_float] = content_auxiliar[columns_to_float].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_textos = [\"Title\", \"Plot\"]\n",
    "variaveis_categoricas = [\"Rated\", \"Director\", \"Production\"] # variaveis para tratar \"Language\", Writer, Actors, Country\n",
    "variaveis_data = [\"Released\", \"Year\", \"DVD\"] # Todas faltam tratar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Year</th>\n",
       "      <th>Released</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Writer</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Language</th>\n",
       "      <th>Country</th>\n",
       "      <th>Awards</th>\n",
       "      <th>Type</th>\n",
       "      <th>DVD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9f0f895fb</td>\n",
       "      <td>1894</td>\n",
       "      <td>09 Jan 1894</td>\n",
       "      <td>Documentary, Short</td>\n",
       "      <td>None</td>\n",
       "      <td>Fred Ott</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>1 win</td>\n",
       "      <td>movie</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d3d9446802</td>\n",
       "      <td>1895</td>\n",
       "      <td>22 Mar 1895</td>\n",
       "      <td>Documentary, Short</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>France</td>\n",
       "      <td>None</td>\n",
       "      <td>movie</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemId  Year     Released               Genre Writer    Actors  \\\n",
       "0  c9f0f895fb  1894  09 Jan 1894  Documentary, Short   None  Fred Ott   \n",
       "1  d3d9446802  1895  22 Mar 1895  Documentary, Short   None      None   \n",
       "\n",
       "  Language        Country Awards   Type   DVD  \n",
       "0     None  United States  1 win  movie  None  \n",
       "1     None         France   None  movie  None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_auxiliar.drop(columns=columns_to_float+variaveis_textos+variaveis_categoricas).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_to_train = content_auxiliar[[\"ItemId\"] + columns_to_float + variaveis_categoricas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma as colunas em numericas: Runtime\n",
    "\n",
    "# usar o catboost para categoria e para suportar NA...\n",
    "# transformar em categorias... Genre, Director, Writer, Actors, Language, Country, Type, Production\n",
    "\n",
    "# Year transformar em anos ate 2025\n",
    "# Released, DVD transformar em dias ate 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "\n",
    "# Include all unique item IDs from both ratings and content datasets\n",
    "all_item_ids = list(set(ratings['ItemId'].unique()).union(content_auxiliar['ItemId'].unique()))\n",
    "all_item_ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_to_train = content_to_train.sort_values(\"ItemId\", ignore_index=True)\n",
    "\n",
    "# Verifia se todos os itens estao iguais\n",
    "content_to_train.ItemId.unique().tolist() == all_item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_features = set()\n",
    "# for column in content_to_train.drop(columns=[\"ItemId\"]).columns:\n",
    "#     item_features.update(content_to_train[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = set()\n",
    "for index, row in content_to_train.drop(columns=[\"ItemId\"]).iterrows():\n",
    "    # from pdb import set_trace; set_trace()\n",
    "    item_features.update(row.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the dataset with all user and item IDs\n",
    "dataset.fit(users=ratings['UserId'].unique(),\n",
    "            items=list(all_item_ids),\n",
    "            item_features=item_features) # content_to_train.drop(columns=\"ItemId\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = content_to_train.columns.to_list()\n",
    "features_columns.pop(0)\n",
    "item_features_data = []\n",
    "for index, row in content_to_train.iterrows():\n",
    "    # from pdb import set_trace; set_trace()\n",
    "    item_features_data.append((row[\"ItemId\"], row[features_columns].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_features_data = [i for i in zip(content_to_train.ItemId,\n",
    "#                                      content_to_train.drop(columns=\"ItemId\").values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_features_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature nan not in feature mapping. Call fit first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m item_features_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_item_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/sistema_recomendacao_tp2_versao3/lib/python3.9/site-packages/lightfm/data.py:422\u001b[0m, in \u001b[0;36mDataset.build_item_features\u001b[0;34m(self, data, normalize)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03mBuild a item features matrix out of an iterable of the form\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03m(item id, [list of feature names]) or (item id, {feature name: feature weight}).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m    Matrix of item features.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    414\u001b[0m builder \u001b[38;5;241m=\u001b[39m _FeatureBuilder(\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_item_id_mapping,\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_item_feature_mapping,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    420\u001b[0m )\n\u001b[0;32m--> 422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/sistema_recomendacao_tp2_versao3/lib/python3.9/site-packages/lightfm/data.py:119\u001b[0m, in \u001b[0;36m_FeatureBuilder.build\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    116\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_mapping[_id], \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m datum \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (entity_idx, feature_idx, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_features(datum):\n\u001b[1;32m    120\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(entity_idx, feature_idx, weight)\n\u001b[1;32m    122\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mtocoo()\u001b[38;5;241m.\u001b[39mtocsr()\n",
      "File \u001b[0;32m~/miniconda/envs/sistema_recomendacao_tp2_versao3/lib/python3.9/site-packages/lightfm/data.py:101\u001b[0m, in \u001b[0;36m_FeatureBuilder._process_features\u001b[0;34m(self, datum)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (feature, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_features(features):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_mapping:\n\u001b[0;32m--> 101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not in feature mapping. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCall fit first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(feature)\n\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    106\u001b[0m     feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_mapping[feature]\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (idx, feature_idx, weight)\n",
      "\u001b[0;31mValueError\u001b[0m: Feature nan not in feature mapping. Call fit first."
     ]
    }
   ],
   "source": [
    "item_features_matrix = dataset.build_item_features(item_features_data, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar[columns_to_float] = content_auxiliar[columns_to_float].fillna(-1)\n",
    "content_auxiliar[variaveis_categoricas] = content_auxiliar[variaveis_categoricas].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ratings[[\"UserId\", \"ItemId\", \"Rating\"]].merge(content_auxiliar[[\"ItemId\"] + columns_to_float + variaveis_categoricas], on=\"ItemId\")\n",
    "train_data.set_index([\"UserId\", \"ItemId\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Rating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    task_type=\"GPU\",    \n",
    "    devices='0',\n",
    "    cat_features=variaveis_categoricas\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data.drop(columns=target),\n",
    "          train_data[target],\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preve para os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = targets.merge(content_auxiliar[[\"ItemId\"] + columns_to_float + variaveis_categoricas], on=\"ItemId\")\n",
    "test_data.set_index([\"UserId\", \"ItemId\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao_test = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction = test_data.reset_index()[[\"UserId\", \"ItemId\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction[\"Rating\"] = previsao_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction = target_prediction.sort_values([\"UserId\", \"Rating\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction.to_csv(\"submissoes/catboost_versao_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction = target_prediction.drop(columns=\"Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction.to_csv(\"submissoes/catboost_versao_1_sem_rating.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sistema_recomendacao_tp2_versao3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
