{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# based-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideias:\n",
    "- FEITO: Usar a coluna para no texto\n",
    "- FEITO: Limpar os dados de conteudo\n",
    "- FEITO (lucas): ordenar os itens novos que ficaram por ultimo por popularidade\n",
    "- FEITO: Adicionar o nome da coluna, porque vai indicar o assunto, em conjunto do texto\n",
    "\n",
    "- tunar os hiperparametros\n",
    "- usa a imagem alem do texto\n",
    "- usar algum algoritmo mais simples apenas para usuarios novos, knn para content based\n",
    "- Entender o parametro exclude_unknowns=True do RatioSplit e se tem alguma forma do DMRL gerar previsoes para itens e usuarios novos \n",
    "\n",
    "- paralelizar a previsao\n",
    "Perguntas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils import load_data\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, content, targets = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"TimestampDate\"] = ratings['Timestamp'].dt.date\n",
    "ratings.loc[ratings.Rating == 0, \"Rating\"] = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpar os dados de conteudo\n",
    "\n",
    "- FEITO - Year: deletar o - no texto '2013–'\n",
    "- FEITO - Rated: alterar as diversas formas de escrever NA para NA. Esse e um caso especial\n",
    "- FEITO - alterar as diversas formas de escrever NA para None em todas as coluans\n",
    "- FEITO - Language: tem varias linhas que possuem bizarices como  'None, English' e 'None, French' , 'English, None'...\n",
    "- FEITO - Ratings: criar uma coluna para cada chave do dicionario, entender quais sao todas as chaves que existem\n",
    "\n",
    "-----------------------------------------------\n",
    "Variaveis que nao precisariam ser tratadas com um bert:\n",
    "- Metascore\n",
    "- imdbRating\n",
    "- Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar = content.drop(columns=[\"Poster\", \"Website\", \"Response\", \"Episode\", \"seriesID\", \"Season\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar['Year'] = content_auxiliar['Year'].str.replace('–', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = content.totalSeasons.unique()[0]\n",
    "dict_transform_to_na = {\n",
    "    \"Rated\":['N/A', 'Not Rated', 'Unrated', 'UNRATED', 'NOT RATED'],\n",
    "    \"all\": [nan, 'N/A', 'None', np.nan],\n",
    "}\n",
    "\n",
    "for na_value in dict_transform_to_na[\"all\"]:\n",
    "    content_auxiliar = content_auxiliar.replace(na_value, None)\n",
    "\n",
    "for na_value in dict_transform_to_na[\"Rated\"]:\n",
    "    content_auxiliar['Rated'] = content_auxiliar['Rated'].replace(na_value, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar['Language'] = content_auxiliar['Language'].str.replace('None, ', '')\n",
    "content_auxiliar['Language'] = content_auxiliar['Language'].str.replace(', None', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Internet Movie Database', 'Metacritic', 'Rotten Tomatoes'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entendendo os valores possiveis para a coluna Ratings\n",
    "# A coluna content_auxiliar.Ratings quarda uma lista que posde ter entre 0 e 3 dicionarios. Cada dicionario possui a chave 'Source', 'Value'.\n",
    "num_ratings_per_item = []\n",
    "unique_keys = []\n",
    "rating_sources = []\n",
    "rating_values = []\n",
    "\n",
    "for rating_list in content_auxiliar.Ratings:\n",
    "    num_ratings_per_item.append(len(rating_list))\n",
    "    for rating_dict in rating_list:\n",
    "        for key in rating_dict:\n",
    "            unique_keys.append(key)\n",
    "        rating_sources.append(rating_dict['Source'])\n",
    "        rating_values.append(rating_dict['Value'])\n",
    "\n",
    "set(rating_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "InternetMovieDatabase_list = []\n",
    "Metacritic_list = []\n",
    "RottenTomatoes_list = []\n",
    "for rating_list in content_auxiliar.Ratings:\n",
    "    InternetMovieDatabase_list.append(None)\n",
    "    Metacritic_list.append(None)\n",
    "    RottenTomatoes_list.append(None)\n",
    "    for rating_dict in rating_list:\n",
    "        if rating_dict['Source'] == 'Internet Movie Database':\n",
    "            InternetMovieDatabase_list[-1] = rating_dict['Value']\n",
    "        elif rating_dict['Source'] == 'Metacritic':\n",
    "            Metacritic_list[-1] = rating_dict['Value']\n",
    "        elif rating_dict['Source'] == 'Rotten Tomatoes':\n",
    "            RottenTomatoes_list[-1] = rating_dict['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar['Internet Movie Database'] = InternetMovieDatabase_list\n",
    "content_auxiliar['Metacritic'] = Metacritic_list\n",
    "content_auxiliar['Rotten Tomatoes'] = RottenTomatoes_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar.drop(columns=['Ratings'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apendar a coluna no valor do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_columns = content_auxiliar.columns.to_list()\n",
    "# content_columns.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in content_columns:\n",
    "#     content_auxiliar[column] = content_auxiliar[column].apply(lambda x: f\"{column}: {x}; \" if x is not None else f\"{column}: unknown value; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_processed = content_auxiliar[['ItemId']].copy()\n",
    "# content_processed[\"text\"] = content_auxiliar[content_columns].astype(str).fillna('').agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viabiliza as colunas para um modelo tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar[\"Internet Movie Database\"] = content_auxiliar[\"Internet Movie Database\"].str.split(\"/\").apply(lambda x: x[0] if x is not None else None)\n",
    "content_auxiliar[\"Rotten Tomatoes\"].replace('%', \"\", regex=True, inplace=True)\n",
    "content_auxiliar[\"Metacritic\"].replace('/100', \"\", regex=True, inplace=True)\n",
    "content_auxiliar[\"imdbVotes\"].replace(',', \"\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar[\"BoxOffice\"].replace(',', \"\", regex=True, inplace=True)\n",
    "\n",
    "# O metodo replace nao funcionnou para $, cuidado para nao rodar essa cedula 2 vezes\n",
    "content_auxiliar[\"BoxOffice\"] = content_auxiliar[\"BoxOffice\"].apply(lambda x: x[1:] if x is not None else None) # troca valores $ por \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_auxiliar[\"Runtime\"].replace(' min', \"\", regex=True, inplace=True)\n",
    "mask = content_auxiliar.Runtime.str.contains('h', na=False)\n",
    "content_auxiliar.loc[mask, \"Runtime\"] = content_auxiliar.loc[mask, \"Runtime\"].str.split(\"h\").apply(lambda x: str(int(x[0]) * 60 + int(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_float = ['Runtime', 'Internet Movie Database', 'Metacritic',\n",
    "                    'Rotten Tomatoes', \"imdbVotes\", \"BoxOffice\",\n",
    "                    \"totalSeasons\", \"imdbRating\", \"Metascore\"]  # Falta tartar Awards\n",
    "content_auxiliar[columns_to_float] = content_auxiliar[columns_to_float].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_textos = [\"Title\", \"Plot\"]\n",
    "variaveis_categoricas = [\"Rated\", \"Director\", \"Production\"] # variaveis para tratar \"Language\", Writer, Actors, Country\n",
    "variaveis_data = [\"Released\", \"Year\", \"DVD\"] # Todas faltam tratar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Year</th>\n",
       "      <th>Released</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Writer</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Language</th>\n",
       "      <th>Country</th>\n",
       "      <th>Awards</th>\n",
       "      <th>Type</th>\n",
       "      <th>DVD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9f0f895fb</td>\n",
       "      <td>1894</td>\n",
       "      <td>09 Jan 1894</td>\n",
       "      <td>Documentary, Short</td>\n",
       "      <td>None</td>\n",
       "      <td>Fred Ott</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>1 win</td>\n",
       "      <td>movie</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d3d9446802</td>\n",
       "      <td>1895</td>\n",
       "      <td>22 Mar 1895</td>\n",
       "      <td>Documentary, Short</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>France</td>\n",
       "      <td>None</td>\n",
       "      <td>movie</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemId  Year     Released               Genre Writer    Actors  \\\n",
       "0  c9f0f895fb  1894  09 Jan 1894  Documentary, Short   None  Fred Ott   \n",
       "1  d3d9446802  1895  22 Mar 1895  Documentary, Short   None      None   \n",
       "\n",
       "  Language        Country Awards   Type   DVD  \n",
       "0     None  United States  1 win  movie  None  \n",
       "1     None         France   None  movie  None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_auxiliar.drop(columns=columns_to_float+variaveis_textos+variaveis_categoricas).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_to_train = content_auxiliar[[\"ItemId\"] + columns_to_float + variaveis_categoricas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma as colunas em numericas: Runtime\n",
    "\n",
    "# usar o catboost para categoria e para suportar NA...\n",
    "# transformar em categorias... Genre, Director, Writer, Actors, Language, Country, Type, Production\n",
    "\n",
    "# Year transformar em anos ate 2025\n",
    "# Released, DVD transformar em dias ate 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_to_train[columns_to_float] = content_to_train[columns_to_float].fillna(-1)\n",
    "content_to_train[variaveis_categoricas] = content_to_train[variaveis_categoricas].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "\n",
    "# Include all unique item IDs from both ratings and content datasets\n",
    "all_item_ids = list(set(ratings['ItemId'].unique()).union(content_auxiliar['ItemId'].unique()))\n",
    "all_item_ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_to_train = content_to_train.sort_values(\"ItemId\", ignore_index=True)\n",
    "\n",
    "# Verifia se todos os itens estao iguais\n",
    "content_to_train.ItemId.unique().tolist() == all_item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_features = set()\n",
    "# for column in content_to_train.drop(columns=[\"ItemId\"]).columns:\n",
    "#     item_features.update(content_to_train[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = set()\n",
    "for index, row in content_to_train.drop(columns=[\"ItemId\"]).iterrows():\n",
    "    # from pdb import set_trace; set_trace()\n",
    "    item_features.update(row.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"unknown\" in item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the dataset with all user and item IDs\n",
    "dataset.fit(users=ratings['UserId'].unique(),\n",
    "            items=list(all_item_ids),\n",
    "            item_features=item_features) # content_to_train.drop(columns=\"ItemId\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = content_to_train.columns.to_list()\n",
    "features_columns.pop(0)\n",
    "item_features_data = []\n",
    "for index, row in content_to_train.iterrows():\n",
    "    # from pdb import set_trace; set_trace()\n",
    "    item_features_data.append((row[\"ItemId\"], row[features_columns].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_features_data = [i for i in zip(content_to_train.ItemId,\n",
    "#                                      content_to_train.drop(columns=\"ItemId\").values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_features_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features_matrix = dataset.build_item_features(item_features_data, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<38012x86311 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 329597 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions, _) = dataset.build_interactions(\n",
    "    [(row['UserId'], row['ItemId'], row['Rating']) for _, row in ratings.iterrows()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from os import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 100/100 [01:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f0a7fa84f10>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss='warp')\n",
    "\n",
    "model.fit(interactions, item_features=item_features_matrix, epochs=100, num_threads=cpu_count(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_map, user_feature_map, item_id_map, item_feature_map = dataset.mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           278\n",
       "1           555\n",
       "2          1159\n",
       "3          1533\n",
       "4          1755\n",
       "          ...  \n",
       "616195    36713\n",
       "616196    37003\n",
       "616197    37241\n",
       "616198    37544\n",
       "616199    37894\n",
       "Name: ItemId, Length: 616200, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.UserId.map(user_id_map.get)\n",
    "targets.ItemId.map(item_id_map.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction = targets.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction[\"Rating\"] = model.predict(targets.UserId.map(user_id_map.get).values,\n",
    "                                            targets.ItemId.map(item_id_map.get).values,\n",
    "                                            item_features=item_features_matrix,\n",
    "                                            num_threads=cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ratings[[\"UserId\", \"ItemId\", \"Rating\"]].merge(content_auxiliar[[\"ItemId\"] + columns_to_float + variaveis_categoricas], on=\"ItemId\")\n",
    "train_data.set_index([\"UserId\", \"ItemId\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Rating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    task_type=\"GPU\",    \n",
    "    devices='0',\n",
    "    cat_features=variaveis_categoricas\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data.drop(columns=target),\n",
    "          train_data[target],\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preve para os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = targets.merge(content_auxiliar[[\"ItemId\"] + columns_to_float + variaveis_categoricas], on=\"ItemId\")\n",
    "test_data.set_index([\"UserId\", \"ItemId\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao_test = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction = test_data.reset_index()[[\"UserId\", \"ItemId\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction[\"Rating\"] = previsao_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salva a previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction = target_prediction.sort_values([\"UserId\", \"Rating\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_prediction.to_csv(\"submissoes/catboost_versao_1.csv\", index=False)\n",
    "target_prediction.to_csv(\"submissoes/lightfm_versao_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction = target_prediction.drop(columns=\"Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_prediction.to_csv(\"submissoes/catboost_versao_1_sem_rating.csv\", index=False)\n",
    "target_prediction.to_csv(\"submissoes/lightfm_versao_2_sem_rating.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sistema_recomendacao_tp2_versao3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
